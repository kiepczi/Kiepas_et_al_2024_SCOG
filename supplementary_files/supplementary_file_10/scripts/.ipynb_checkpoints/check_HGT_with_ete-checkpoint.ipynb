{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1582ef6",
   "metadata": {},
   "source": [
    "# check HGT with ete3\n",
    "\n",
    "This notebook was used to check for possible HGT of SCO. \n",
    "\n",
    "Here, we will compare singe gene tree to species tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a29aba1",
   "metadata": {},
   "source": [
    "**Concept**\n",
    "\n",
    "We have a species tree inferred from 136 SCO.\n",
    "\n",
    "To check if there is a possibility for HGT, we check how each SCOG is distibuted across the species tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaa4121",
   "metadata": {},
   "source": [
    "**Set Up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "245f65b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ete3 import Tree\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from Bio import AlignIO\n",
    "import hashlib\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9853fe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_tree = Tree('((((H,K)D,(F,I)G)B,E)A,((L,(N,Q)O)J,(P,S)M)C);', format=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc88f6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is species tree: \n",
      "            /-H\n",
      "         /-|\n",
      "        |   \\-K\n",
      "      /-|\n",
      "     |  |   /-F\n",
      "   /-|   \\-|\n",
      "  |  |      \\-I\n",
      "  |  |\n",
      "  |   \\-E\n",
      "--|\n",
      "  |      /-L\n",
      "  |   /-|\n",
      "  |  |  |   /-N\n",
      "  |  |   \\-|\n",
      "   \\-|      \\-Q\n",
      "     |\n",
      "     |   /-P\n",
      "      \\-|\n",
      "         \\-S\n"
     ]
    }
   ],
   "source": [
    "print(f'This is species tree: {species_tree}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "552affbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is gene tree:\n",
      "   /-HK\n",
      "  |\n",
      "--|      /-FIE\n",
      "  |   /-|\n",
      "  |  |   \\-L\n",
      "   \\-|\n",
      "     |   /-NQ\n",
      "      \\-|\n",
      "         \\-PS\n"
     ]
    }
   ],
   "source": [
    "gene_tree = Tree('(HK, ((FIE,L), (NQ,PS)));')\n",
    "print(f'This is gene tree:{gene_tree}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493c4893",
   "metadata": {},
   "source": [
    "1. First, we can be interested in the leave/clade `HK` in the gene tree, and check first common ancestor for H and F in the species tree.\n",
    "\n",
    "If the first common ancestor just includes `H` and `K`, then we can conclude there is no HGT taking place.\n",
    "\n",
    "If however other `species` will be found, then there is a posibility that HGT has likely occured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c56394d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common ancestor for H and K in species tree is: ['H', 'K']\n"
     ]
    }
   ],
   "source": [
    "ancestor = species_tree.get_common_ancestor(\"H\", \"K\")\n",
    "print(f\"Most common ancestor for H and K in species tree is: {[_.name for _ in ancestor]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe31e5ca",
   "metadata": {},
   "source": [
    "2. We can now investigate `F`, `I` and `E`. \n",
    "\n",
    "Here, the HGT has likely occured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b05ebc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common ancestor for F, I and K in species tree is: ['H', 'K', 'F', 'I', 'E']\n"
     ]
    }
   ],
   "source": [
    "ancestor = species_tree.get_common_ancestor(\"F\", \"I\", 'E')\n",
    "print(f\"Most common ancestor for F, I and K in species tree is: {[_.name for _ in ancestor]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a512490",
   "metadata": {},
   "source": [
    "**Loading our species tree and roothing them at midpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03fcf175",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_tree = Tree(\"../../supplementary_file_5/output/tree/04_tbe.raxml.support\")\n",
    "R = species_tree.get_midpoint_outgroup()\n",
    "# and set it as tree outgroup\n",
    "species_tree.set_outgroup(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a82fe0a",
   "metadata": {},
   "source": [
    "**Step 1**\n",
    "When calculating the species tree, we concatenated the SCO alignments, and removed gaps with trimAl. \n",
    "We have also retained information about the alignments partitions, eg. which columns in the MSA represent the SCO. We can use this information to extract the columns of interest (for each individual SCO), and see how identical sequences are disibuted across the tree.\n",
    "\n",
    "So, here we first extract individual aligments for each SCO from the concatenated and trimmed SCO aligment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36717c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aligments(SCO, start, end):\n",
    "    \n",
    "    alignment = AlignIO.read(Path(\"../../supplementary_file_5/output/alignments/concatenated/no_gaps_concatenated_sco.fasta\").expanduser(), \"fasta\")    \n",
    "    \n",
    "    AlignIO.write(alignment[:, start:end], Path(f\"../output/SCOGs_sequences/{SCO}.fasta\").expanduser(), \"fasta\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86fd5742",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(\"../../supplementary_file_5/output/alignments/concatenated/concatenated_modeltest_fixed_positions.part\").expanduser()\n",
    "\n",
    "# Open the file\n",
    "with open(file_path, 'r') as file:\n",
    "    # Read the file line by line\n",
    "    for line in file:\n",
    "        SCO = line.strip().split(', ')[-1].split('_')[0]\n",
    "        start = int(line.strip().split(', ')[-1].split('= ')[1].split('-')[0])-1\n",
    "        end = line.strip().split(', ')[-1].split('= ')[1].split('-')[1]\n",
    "        get_aligments(SCO, int(start), int(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67cd95d",
   "metadata": {},
   "source": [
    "**Step 2** using Hashing method we can now check which species share the same nucleotide sequence, and whether they form monophyletic caneds on the species tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0835667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_HGT_and_assign_colour_for_viz(species_tree, alignment):\n",
    "    \"\"\"Return dictionary with diffrent colour for each nucleotide variant if possible HGT.\n",
    "    If HGT unlikely do not assign colour.\n",
    "    \n",
    "    :param species_tree: species phylogenetic tree\n",
    "    :param gene_tree: single gene tree\n",
    "    \"\"\"\n",
    "    \n",
    "    clusters = defaultdict(list)\n",
    "    \n",
    "    alignment = AlignIO.read(alignment, \"fasta\")\n",
    "    \n",
    "    #Getting dictionary with genomes sharing the same nucleotide sequence keyed by the sequence hash\n",
    "    for _ in alignment:\n",
    "        clusters[hashlib.md5(str(_.seq).encode('utf-8')).hexdigest()].append(_.name)\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    HGT_variants = {}\n",
    "    colours = {}\n",
    "    HGT_predictions = {}\n",
    "\n",
    "    #Check for HGT\n",
    "    current = 0\n",
    "    for cluster, genomes in clusters.items():\n",
    "        if len(genomes) !=1: #Only consider genomes that were collapsed eg. share the same nt sequence with at least 1 more genome\n",
    "            ancestor = species_tree.get_common_ancestor(genomes) #Get first common ancestor\n",
    "            if sorted(genomes) != sorted([_.name for _ in ancestor]): #Check if the group possible affected by HGT\n",
    "                current +=1\n",
    "                for _ in genomes:\n",
    "                    HGT_variants[_] = current\n",
    "                    HGT_predictions[_] = 'True'\n",
    "                    HGT_variants[_] = str(current)\n",
    "    \n",
    "    \n",
    "    palette = sns.color_palette(\"Spectral\", len(set(HGT_variants.values())))\n",
    "    palette=palette.as_hex()\n",
    "\n",
    "    x = dict(zip(list(set(HGT_variants.values())), palette))\n",
    "    \n",
    "    for HGT_variant, colour in x.items():\n",
    "        for genome, variant in HGT_variants.items():\n",
    "\n",
    "            if HGT_variant == variant:\n",
    "                colours[genome] = colour\n",
    "    \n",
    "    return colours, HGT_predictions, HGT_variants\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "286d2221",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz = pd.DataFrame({'Name': [_.name for _ in species_tree]})\n",
    "df_HGT = pd.DataFrame({'Name': [_.name for _ in species_tree]})\n",
    "df_variants = pd.DataFrame({'Name': [_.name for _ in species_tree]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91672c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = Path(\"../output/SCOGs_sequences\").expanduser()\n",
    "filenames = sorted(datadir.glob(\"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a925798d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q5/_y5sk7t54698g_zl8yghqkmc0000gn/T/ipykernel_6035/674441215.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_viz[SCO]= df_viz.Name.map(viz_data).fillna('#F0F0F0')\n",
      "/var/folders/q5/_y5sk7t54698g_zl8yghqkmc0000gn/T/ipykernel_6035/674441215.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_HGT[SCO]= df_HGT.Name.map(HGT_data).fillna('False')\n",
      "/var/folders/q5/_y5sk7t54698g_zl8yghqkmc0000gn/T/ipykernel_6035/674441215.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_variants[SCO]= df_variants.Name.map(HGT_variants).fillna('0')\n"
     ]
    }
   ],
   "source": [
    "for _ in filenames:\n",
    "    SCO = str(_).split('/')[-1].split('.')[0]\n",
    "    viz_data, HGT_data, HGT_variants = check_HGT_and_assign_colour_for_viz(species_tree, _)\n",
    "    df_viz[SCO]= df_viz.Name.map(viz_data).fillna('#F0F0F0')\n",
    "    df_HGT[SCO]= df_HGT.Name.map(HGT_data).fillna('False')\n",
    "    df_variants[SCO]= df_variants.Name.map(HGT_variants).fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d57964f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz.to_csv(Path(\"../output/SCOGs_distribution_vizualisation_data.csv\").expanduser(), index=False)\n",
    "df_HGT.to_csv(Path(\"../output/HGT_predictions_data.csv\").expanduser(), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9ebd0",
   "metadata": {},
   "source": [
    "**Step 3**\n",
    "for vizualization reduce number of data by removing columns/SCO where no HGT is predicted, and sort the values from least to most diverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4eff15f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz = df_viz.set_index('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d2566fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz_reduced = df_viz.loc[:, (df_viz != '#F0F0F0').any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbc1ce29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OG0002083</th>\n",
       "      <th>OG0002171</th>\n",
       "      <th>OG0002192</th>\n",
       "      <th>OG0002202</th>\n",
       "      <th>OG0002242</th>\n",
       "      <th>OG0002247</th>\n",
       "      <th>OG0002077</th>\n",
       "      <th>OG0002081</th>\n",
       "      <th>OG0002116</th>\n",
       "      <th>OG0002125</th>\n",
       "      <th>...</th>\n",
       "      <th>OG0002193</th>\n",
       "      <th>OG0002194</th>\n",
       "      <th>OG0002120</th>\n",
       "      <th>OG0002282</th>\n",
       "      <th>OG0002167</th>\n",
       "      <th>OG0002191</th>\n",
       "      <th>OG0002080</th>\n",
       "      <th>OG0002076</th>\n",
       "      <th>OG0002086</th>\n",
       "      <th>OG0002082</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GCF_000717725.1</th>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>...</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCF_900105395.1</th>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>...</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCF_000380165.1</th>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>...</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCF_000745345.1</th>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>...</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCF_000813365.1</th>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>...</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCF_000718455.1</th>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>...</td>\n",
       "      <td>#a7dba4</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#466eb1</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#f3faac</td>\n",
       "      <td>#eff9a6</td>\n",
       "      <td>#fbfdb8</td>\n",
       "      <td>#69c3a5</td>\n",
       "      <td>#e3534a</td>\n",
       "      <td>#fff3ac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCF_016901035.1</th>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>...</td>\n",
       "      <td>#a7dba4</td>\n",
       "      <td>#fcaa5f</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#fff7b2</td>\n",
       "      <td>#f3faac</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#fbfdb8</td>\n",
       "      <td>#ffffbe</td>\n",
       "      <td>#e3534a</td>\n",
       "      <td>#d63f4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCF_016906245.1</th>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>...</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#f3faac</td>\n",
       "      <td>#eff9a6</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#69c3a5</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCF_001905905.1</th>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>...</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#466eb1</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#f3faac</td>\n",
       "      <td>#eff9a6</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#69c3a5</td>\n",
       "      <td>#e3534a</td>\n",
       "      <td>#F0F0F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCF_002551145.1</th>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>...</td>\n",
       "      <td>#4471b2</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#f3faac</td>\n",
       "      <td>#71c6a5</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#F0F0F0</td>\n",
       "      <td>#e3534a</td>\n",
       "      <td>#fcfeba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                OG0002083 OG0002171 OG0002192 OG0002202 OG0002242 OG0002247  \\\n",
       "Name                                                                          \n",
       "GCF_000717725.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   \n",
       "GCF_900105395.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   \n",
       "GCF_000380165.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   \n",
       "GCF_000745345.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   \n",
       "GCF_000813365.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "GCF_000718455.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   \n",
       "GCF_016901035.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   \n",
       "GCF_016906245.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   \n",
       "GCF_001905905.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   \n",
       "GCF_002551145.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   \n",
       "\n",
       "                OG0002077 OG0002081 OG0002116 OG0002125  ... OG0002193  \\\n",
       "Name                                                     ...             \n",
       "GCF_000717725.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0  ...   #F0F0F0   \n",
       "GCF_900105395.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0  ...   #F0F0F0   \n",
       "GCF_000380165.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0  ...   #F0F0F0   \n",
       "GCF_000745345.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0  ...   #F0F0F0   \n",
       "GCF_000813365.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0  ...   #F0F0F0   \n",
       "...                   ...       ...       ...       ...  ...       ...   \n",
       "GCF_000718455.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0  ...   #a7dba4   \n",
       "GCF_016901035.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0  ...   #a7dba4   \n",
       "GCF_016906245.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0  ...   #F0F0F0   \n",
       "GCF_001905905.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0  ...   #F0F0F0   \n",
       "GCF_002551145.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0  ...   #4471b2   \n",
       "\n",
       "                OG0002194 OG0002120 OG0002282 OG0002167 OG0002191 OG0002080  \\\n",
       "Name                                                                          \n",
       "GCF_000717725.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   \n",
       "GCF_900105395.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   \n",
       "GCF_000380165.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   \n",
       "GCF_000745345.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   \n",
       "GCF_000813365.1   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   #F0F0F0   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "GCF_000718455.1   #F0F0F0   #466eb1   #F0F0F0   #f3faac   #eff9a6   #fbfdb8   \n",
       "GCF_016901035.1   #fcaa5f   #F0F0F0   #fff7b2   #f3faac   #F0F0F0   #fbfdb8   \n",
       "GCF_016906245.1   #F0F0F0   #F0F0F0   #F0F0F0   #f3faac   #eff9a6   #F0F0F0   \n",
       "GCF_001905905.1   #F0F0F0   #466eb1   #F0F0F0   #f3faac   #eff9a6   #F0F0F0   \n",
       "GCF_002551145.1   #F0F0F0   #F0F0F0   #F0F0F0   #f3faac   #71c6a5   #F0F0F0   \n",
       "\n",
       "                OG0002076 OG0002086 OG0002082  \n",
       "Name                                           \n",
       "GCF_000717725.1   #F0F0F0   #F0F0F0   #F0F0F0  \n",
       "GCF_900105395.1   #F0F0F0   #F0F0F0   #F0F0F0  \n",
       "GCF_000380165.1   #F0F0F0   #F0F0F0   #F0F0F0  \n",
       "GCF_000745345.1   #F0F0F0   #F0F0F0   #F0F0F0  \n",
       "GCF_000813365.1   #F0F0F0   #F0F0F0   #F0F0F0  \n",
       "...                   ...       ...       ...  \n",
       "GCF_000718455.1   #69c3a5   #e3534a   #fff3ac  \n",
       "GCF_016901035.1   #ffffbe   #e3534a   #d63f4f  \n",
       "GCF_016906245.1   #69c3a5   #F0F0F0   #F0F0F0  \n",
       "GCF_001905905.1   #69c3a5   #e3534a   #F0F0F0  \n",
       "GCF_002551145.1   #F0F0F0   #e3534a   #fcfeba  \n",
       "\n",
       "[295 rows x 38 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Step 1: Calculate the number of unique values in each column\n",
    "unique_counts = df_viz_reduced.nunique()\n",
    "\n",
    "# Step 2: Create a dictionary with column names and unique value counts\n",
    "column_dict = dict(unique_counts)\n",
    "\n",
    "# Step 3: Sort the dictionary by values in ascending order\n",
    "sorted_columns = sorted(column_dict, key=column_dict.get)\n",
    "\n",
    "# Step 4: Extract the sorted column names\n",
    "sorted_column_names = list(sorted_columns)\n",
    "\n",
    "# Step 5: Reorder the DataFrame columns based on the sorted column names\n",
    "df_viz_reduced = df_viz_reduced[sorted_column_names]\n",
    "\n",
    "# Print the reordered DataFrame\n",
    "df_viz_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f60c4e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz_reduced.to_csv(Path(\"../output/SCOGs_distribution_vizualisation_data_reduced.csv\").expanduser())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84999577",
   "metadata": {},
   "source": [
    "**Checking if the SCO variants that do not form monophyletic are scattered across multiple candidate genus.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2df5a0",
   "metadata": {},
   "source": [
    "This will be done in the dollowing steps:\n",
    "- Step 1: Get columns of interest such as those where HGT was suspected. \n",
    "- Step 2: Write funcion that will get dictionary with list of genomes sharing the same variant keyed by the variant assigned number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa86227a",
   "metadata": {},
   "source": [
    "*Step 1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b341991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variants_reduced = df_variants.loc[:, (df_variants != '0').any(axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee1df6e",
   "metadata": {},
   "source": [
    "*Step 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4038808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variant_counts(data, column1, column2):\n",
    "    \n",
    "    result_dict = defaultdict(list)\n",
    "    \n",
    "    # Iterate over the columns\n",
    "    for key, value in zip(data[column2], data[column1]):\n",
    "        if key != '0':\n",
    "            result_dict[key].append(value)\n",
    "\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "372b8288",
   "metadata": {},
   "outputs": [],
   "source": [
    "genus_data = pd.read_csv(Path(\"../../supplementary_file_10/output/pyANI_genus_IDs.csv\").expanduser()).set_index('accession').to_dict()['genus_ID_pc_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3228373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_viz_data(genus_dictionary, variants_dictionary, SCOG):\n",
    "    \n",
    "    genus_representation_per_variant = defaultdict(list)\n",
    "    suspected_genomes = []\n",
    "    \n",
    "    colours = {}\n",
    "    \n",
    "    #Getting dictionary with list of genus occurence of a given SCOG variant\n",
    "    for variant, genomes in variants_dictionary.items():\n",
    "        for genome in genomes:\n",
    "            genus_representation_per_variant[variant].append(genus_dictionary[genome])\n",
    "            \n",
    "    #Getting list of variants that are present across multiple genus\n",
    "    variants_of_interest = [variant for variant, genus in genus_representation_per_variant.items() if len(list(set(genus))) != 1]\n",
    "\n",
    "    #Getting list of genomes that share the variants of interest\n",
    "    for variant, genomes in variants_dictionary.items():\n",
    "        if variant in variants_of_interest:\n",
    "            suspected_genomes.extend(genomes)\n",
    "            \n",
    "    #Extracting colours\n",
    "    current_colours = pd.read_csv(Path(\"../output/SCOGs_distribution_vizualisation_data.csv\").expanduser()).set_index('Name').to_dict()[SCOG]\n",
    "    \n",
    "    for genome, colour in current_colours.items():\n",
    "        if genome in suspected_genomes:\n",
    "            colours[genome] = colour\n",
    "            \n",
    "            \n",
    "    return colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79634ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz = pd.DataFrame({'Name': [_.name for _ in species_tree]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00bab9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for SCOG in df_variants_reduced:\n",
    "    if SCOG != 'Name':\n",
    "        genomes_per_variants = get_variant_counts(df_variants_reduced, 'Name', SCOG)\n",
    "        x = get_viz_data(genus_data, genomes_per_variants, SCOG)\n",
    "        if len(x) != 0:\n",
    "            df_viz[SCOG]= df_viz.Name.map(x).fillna('#F0F0F0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbd72150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz.to_csv(Path(\"../output/SCOGs_distribution_vizualisation_data_genus_split.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afa1e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
