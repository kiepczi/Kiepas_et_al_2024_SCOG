{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1c58485",
   "metadata": {},
   "source": [
    "# Assign genus IDs based on pyANI analysis, and piecewise linear regression boundaries, and other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3424ba7c",
   "metadata": {},
   "source": [
    "**Set Up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c41caab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import dwave_networkx as dnx\n",
    "import ete3\n",
    "from ete3 import Tree, TreeStyle, faces\n",
    "from ete3 import PhyloNode\n",
    "from ete3 import NodeStyle\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd0836c",
   "metadata": {},
   "source": [
    "**Loading data**\n",
    "Here we are interested in coverage and identity matrices from pyANI analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ba7e1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = pd.read_csv(Path(\"../../supplementary_file_3/output/pyani_matrices/matrix_identity_1.tab\"), sep='\\t').rename(columns={'Unnamed: 0': 'genome1'})\n",
    "coverage = pd.read_csv(Path(\"../../supplementary_file_3/output/pyani_matrices/matrix_coverage_1.tab\"), sep='\\t').rename(columns={'Unnamed: 0': 'genome1'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1faf9e6",
   "metadata": {},
   "source": [
    "**Assigning species and genus ID**\n",
    "Here, we:\n",
    "- write a function that removes suffix provided in the pyANI matrices\n",
    "- get a function that will use provided dataframe to calculate MST, and remove edges between genomes if their thereshold is lower than the one provided. In case, where cliques are present it will keep removing the lowest weight until no cliques are present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e97f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_suffix(row, col):\n",
    "    \"\"\"Return accession number from 'FILE' column.\"\"\"\n",
    "\n",
    "    try:\n",
    "        new = ' '.join(row[col].split(':')[:-1])\n",
    "    except IndexError:\n",
    "        new = 'NA'\n",
    "\n",
    "    return new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a334a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_ANI_tax_ID_one_attribute(df, thereshold, attribute, ANI_ID):\n",
    "        \"\"\"Assign taxon IDs based on ANI analysis. \n",
    "        \n",
    "        :param df: dataframe with each row providing pyANI identity and coverage for a given parir of genomes\n",
    "        :param thereshold: thereshold at which genomes should be separated (num)\n",
    "        :param attribute: comparision type deciding which should be used to separate genomes identity or coverage\n",
    "        :param ANI_ID: current number of assigned IDs\n",
    "        \"\"\"\n",
    "        \n",
    "        #Generate NetworkX grah with identity and coverage as edge attibutes \n",
    "        G_comp=nx.from_pandas_edgelist(df, 'genome1', 'genome2', ['identity', 'coverage'])\n",
    "        \n",
    "        current_assignments = {} #Hold empty dictionary\n",
    "\n",
    "        ANI_ID = ANI_ID\n",
    "\n",
    "        #Remove edges if thereshold for a given attribute is lower \n",
    "        edges_to_remove = [(n1,n2) for n1, n2, attrs in G_comp.edges(data=True) if attrs[attribute] < thereshold]\n",
    "        G_comp.remove_edges_from(edges_to_remove)\n",
    "        \n",
    "        #Check if the components are clique, if not remove edges until clique is achived\n",
    "        components = [_ for _ in list(nx.connected_components(G_comp))]\n",
    "        for component in components:\n",
    "            while dnx.is_clique(G_comp, component) == False:\n",
    "                weights = sorted(list(set([attrs[attribute] for n1, n2, attrs in G_comp.edges(data=True) if n1 in component and n2 in component])))\n",
    "                edges_to_remove = [(n1,n2) for n1, n2, attrs in G_comp.edges(data=True) if attrs[attribute] < (weights)[1] and n1 in component and n2 in component]\n",
    "                G_comp.remove_edges_from(edges_to_remove)\n",
    "                weights.remove(weights[0])\n",
    "\n",
    "                components = [_ for _ in list(nx.connected_components(G_comp))]\n",
    "                for component in components:\n",
    "                    if dnx.is_clique(G_comp, component) == True:\n",
    "                        break\n",
    "        #Assign IDs\n",
    "        components = [_ for _ in list(nx.connected_components(G_comp))]\n",
    "        for component in components:\n",
    "            current_assignments.update({_:ANI_ID for _ in component})\n",
    "            ANI_ID += 1\n",
    "\n",
    "    \n",
    "        return current_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c85a82c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_species_ID = 1\n",
    "current_genus_ID = 1\n",
    "genome_genus_ID = {}\n",
    "genome_species_ID = {}\n",
    "                   #Melting data\n",
    "identity_melt = pd.melt(identity, id_vars=['genome1'], value_vars=[_ for _ in identity if _ != 'genome1'], var_name='genome2', value_name='identity')\n",
    "coverage_melt = pd.melt(coverage, id_vars=['genome1'], value_vars=[_ for _ in identity if _ != 'genome1'], var_name='genome2', value_name='coverage')\n",
    "    \n",
    "                    #Combine data\n",
    "combined = pd.merge(identity_melt, coverage_melt,  how='left', left_on=['genome1', 'genome2'], right_on = ['genome1','genome2'])\n",
    "combined = combined[combined['genome1'] != combined['genome2']] #Remove self-to-self comparisions\n",
    "                    #Remove duplicate comparisions and keep minimum coverage and average identity\n",
    "combined[['genome1','genome2']] = np.sort(combined[['genome1','genome2']].to_numpy(),axis=1)\n",
    "fixed = (combined.groupby(['genome1','genome2']).agg(identity = ('identity','mean'), coverage = ('coverage','min')).reset_index())\n",
    "fixed[\"genome1\"] = fixed.apply(remove_suffix,col='genome1', axis=1)\n",
    "fixed['genome2'] = fixed.apply(remove_suffix,col='genome2', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a69d320",
   "metadata": {},
   "source": [
    "**Generate dataframe to which we will append information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62831de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Path(\"../../supplementary_file_3/input/custom_labels.txt\"), sep='\\t', names=['MD5_hash', 'FILE', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ade52df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accession(row):\n",
    "    \"\"\"Return accession number from 'FILE' column.\"\"\"\n",
    "\n",
    "    try:\n",
    "        acc = '_'.join(row['FILE'].split('_')[:2])\n",
    "    except IndexError:\n",
    "        acc = 'NA'\n",
    "\n",
    "    return acc\n",
    "\n",
    "df[\"accession\"] = df.apply(get_accession, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa892dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['MD5_hash']\n",
    "del df['FILE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7884fb1f",
   "metadata": {},
   "source": [
    "**Assigning genus IDs using boundries with 3 segment piecewise regression**\n",
    "\n",
    "Here, we only consider one attribute; genome coverage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3722e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Genus ID\n",
    "groups = assign_ANI_tax_ID_one_attribute(fixed, 0.459, 'coverage', current_genus_ID)\n",
    "labels_to_accession = df.set_index('label').to_dict()['accession']\n",
    "genome_genus_ID = {labels_to_accession[label]:genus_ID for label,genus_ID in groups.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f4e4b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genus_ID_pc_3'] = df['accession'].map(genome_genus_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dc645b",
   "metadata": {},
   "source": [
    "**Assigning genus IDs using boundries with 2 segment piecewise regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d20803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = assign_ANI_tax_ID_one_attribute(fixed, 0.498, 'coverage', current_genus_ID)\n",
    "labels_to_accession = df.set_index('label').to_dict()['accession']\n",
    "genome_genus_ID = {labels_to_accession[label]:genus_ID for label,genus_ID in groups.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6e7ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genus_ID_pc_2'] = df['accession'].map(genome_genus_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd68f2b",
   "metadata": {},
   "source": [
    "**Assigining genus/species IDs based on two attributes.**\n",
    "\n",
    "Here, we will write a function that will assign genomes to candidate genus and/or species by considering both genome coverage and genome identity. \n",
    "\n",
    "The function will work in the following steps:\n",
    "- Create a complete graph, where each genome/node is connected to evry other genome/node\n",
    "- Assign genome coverage and genome identity as edges attributes\n",
    "- Remove edges if the thereshold for genome covera is lower than the one provodes. In case, where cliques are present it will keep removing the lowest weigh until no cliques are present. \n",
    "- Then, we will do the same but this time with genome identity for a given/specified genome identity threshold. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41386243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_ANI_tax_ID_two_attribute(df, threshold_1, attribute_1, ANI_ID, attribute_2, threshold_2):\n",
    "        \"\"\"Assign taxon IDs based on ANI analysis. \n",
    "        \n",
    "        :param df: dataframe with each row providing pyANI identity and coverage for a given parir of genomes\n",
    "        :param thereshold: thereshold at which genomes should be separated (num)\n",
    "        :param attribute: comparision type deciding which should be used to separate genomes identity or coverage\n",
    "        :param ANI_ID: current number of assigned IDs\n",
    "        \"\"\"\n",
    "        \n",
    "        #Generate NetworkX grah with identity and coverage as edge attibutes \n",
    "        G_comp=nx.from_pandas_edgelist(df, 'genome1', 'genome2', ['identity', 'coverage'])\n",
    "        \n",
    "        current_assignments = {} #Hold empty dictionary\n",
    "\n",
    "        ANI_ID = ANI_ID\n",
    "\n",
    "        \n",
    "        \n",
    "        edges_to_remove = [(n1,n2) for n1, n2, attrs in G_comp.edges(data=True) if attrs[attribute_1] < threshold_1 or attrs[attribute_2] < threshold_2]\n",
    "        G_comp.remove_edges_from(edges_to_remove)\n",
    "        \n",
    "        \n",
    "        #Check if the components are clique, if not remove edges until clique is achived\n",
    "        components = [_ for _ in list(nx.connected_components(G_comp))]\n",
    "        for component in components:\n",
    "            while dnx.is_clique(G_comp, component) == False:\n",
    "                weights = sorted(list(set([attrs[attribute_1] for n1, n2, attrs in G_comp.edges(data=True) if n1 in component and n2 in component])))\n",
    "                edges_to_remove = [(n1,n2) for n1, n2, attrs in G_comp.edges(data=True) if attrs[attribute_1] < (weights)[1] and n1 in component and n2 in component]\n",
    "                G_comp.remove_edges_from(edges_to_remove)\n",
    "                weights.remove(weights[0])\n",
    "\n",
    "                components = [_ for _ in list(nx.connected_components(G_comp))]\n",
    "                for component in components:\n",
    "                    if dnx.is_clique(G_comp, component) == True:\n",
    "                        break\n",
    "        #Assign IDs\n",
    "        components = [_ for _ in list(nx.connected_components(G_comp))]\n",
    "        for component in components:\n",
    "            current_assignments.update({_:ANI_ID for _ in component})\n",
    "            ANI_ID += 1\n",
    "\n",
    "    \n",
    "        return current_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "487422a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = fixed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d16773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = assign_ANI_tax_ID_two_attribute(fixed, 0.4590, 'coverage', current_genus_ID, 'identity', 0.868)\n",
    "labels_to_accession = df.set_index('label').to_dict()['accession']\n",
    "genome_genus_ID = {labels_to_accession[label]:genus_ID for label,genus_ID in groups.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf732b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genus_ID_pc_3_with_ID'] = df['accession'].map(genome_genus_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22309120",
   "metadata": {},
   "source": [
    "**Checking if the groups are monophyletic in SCO tree.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1085b9d0",
   "metadata": {},
   "source": [
    "One of the main objectives of carrying this anlysis was to identify biologically meaningful groups for pangenomic analysis. \n",
    "\n",
    "After mapping the identified genus for genome coverage theresholds identified by piecewise regression, it was found that the groups do not form monophyletic groups on SCO tree. \n",
    "\n",
    "Therefore, to find groupings in which that problem does not occur the analysis will be run at starting genome coverage between 40% and 60% in steps of 0.1%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cce62d3",
   "metadata": {},
   "source": [
    "**Check monophyly**\n",
    "\n",
    "Writing function that will check if a given set of genomes form monophyletic caldes in the SCO phylogenetic tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2065f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_monophyly(tree, group):\n",
    "    \"\"\"Return True if teh given group\n",
    "    is monophyletic, otherwise return False.\n",
    "    \"\"\"\n",
    "    \n",
    "    monophyly_status = tree.check_monophyly(values=group, target_attr=\"name\", ignore_missing=True)[0]\n",
    "    \n",
    "    \n",
    "    return monophyly_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "850647c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCO_tree = Tree('../../supplementary_file_5/output/tree/04_tbe.raxml.support', format=1)\n",
    "\n",
    "R = SCO_tree.get_midpoint_outgroup()\n",
    "# and set it as tree outgroup\n",
    "SCO_tree.set_outgroup(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03645dff",
   "metadata": {},
   "source": [
    "**Assigning genus IDs with starting genome coverage between 45% and 55% in steps of 0.1%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba81af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "genus_df = pd.DataFrame(columns=['coverage_threshold', 'clusters', 'singletons', 'monophyletic', 'non_monophyletic'])\n",
    "\n",
    "for i in np.arange(0.400, 0.851, 0.001):\n",
    "    \n",
    "    cluster_members = defaultdict(list) #Hold an empty defaultdict; here members of the same group will be keyed by asigned genus ID\n",
    "    groups = assign_ANI_tax_ID_one_attribute(fixed, round(i, 3), 'coverage', current_genus_ID) #Assigning genus IDs\n",
    "    labels_to_accession = df.set_index('label').to_dict()['accession']\n",
    "    genome_genus_ID = {labels_to_accession[label]:genus_ID for label,genus_ID in groups.items()} #Mapping genome accessions\n",
    "    #Get cluster/genus ID members\n",
    "    for genome, genus_ID in genome_genus_ID.items():\n",
    "        cluster_members[genus_ID].append(genome)\n",
    "    \n",
    "    no_of_monophyletic_groups = 0\n",
    "    no_of_non_monophyletic_groups = 0\n",
    "    singleton = 0\n",
    "    #Check monophyly of all groups with at least 2 genomes\n",
    "    for k, v in cluster_members.items():\n",
    "        if len(v) !=1:\n",
    "            monophyly_stat = check_monophyly(SCO_tree, v)\n",
    "            if monophyly_stat == True:\n",
    "                no_of_monophyletic_groups +=1\n",
    "            else:\n",
    "                no_of_non_monophyletic_groups += 1\n",
    "        else:\n",
    "            singleton += 1\n",
    "    genus_df.loc[len(genus_df)] = [round(i*100, 3), len(cluster_members), singleton ,int(no_of_monophyletic_groups), int(no_of_non_monophyletic_groups)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca22bc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "genus_df[['clusters', 'singletons', 'monophyletic', 'non_monophyletic']] = genus_df[['clusters', 'singletons', 'monophyletic', 'non_monophyletic']].applymap(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fff2d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "genus_df.to_csv(Path(\"../output/monophyly_status.csv\").expanduser(), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e3ebe4",
   "metadata": {},
   "source": [
    "**Reorder df**\n",
    "\n",
    "Here, we will reorder dataframe so that the accessions match the ordering of the leave nodes in the SCO tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31e76eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(Path(\"../../supplementary_file_5/output/SCOG_tree_node_order.csv\").expanduser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51331ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.merge(data2, df, on='accession')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee288804",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data2['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a092249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accession</th>\n",
       "      <th>genus_ID_pc_3</th>\n",
       "      <th>genus_ID_pc_2</th>\n",
       "      <th>genus_ID_pc_3_with_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GCF_000709915.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GCF_018966745.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GCF_900079415.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GCF_000719785.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GCF_002899455.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>GCF_000813365.1</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>GCF_000745345.1</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>GCF_900105395.1</td>\n",
       "      <td>42</td>\n",
       "      <td>47</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>GCF_000717725.1</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>GCF_000380165.1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           accession  genus_ID_pc_3  genus_ID_pc_2  genus_ID_pc_3_with_ID\n",
       "0    GCF_000709915.1              5              5                      5\n",
       "1    GCF_018966745.1              5              5                      5\n",
       "2    GCF_900079415.1              5              5                      5\n",
       "3    GCF_000719785.1              5              5                      5\n",
       "4    GCF_002899455.1              5              5                      5\n",
       "..               ...            ...            ...                    ...\n",
       "290  GCF_000813365.1             28             29                     28\n",
       "291  GCF_000745345.1             27             27                     27\n",
       "292  GCF_900105395.1             42             47                     43\n",
       "293  GCF_000717725.1             19             19                     19\n",
       "294  GCF_000380165.1             11             11                     11\n",
       "\n",
       "[295 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95c053f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_csv(Path(\"../output/pyANI_genus_IDs.csv\").expanduser(), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
